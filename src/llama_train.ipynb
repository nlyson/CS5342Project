{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Dependencies</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, UnstructuredWordDocumentLoader, PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "import pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Embed Class Slides and Textbooks</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 7 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 32 0 (offset 0)\n",
      "Ignoring wrong pointing object 34 0 (offset 0)\n",
      "Ignoring wrong pointing object 41 0 (offset 0)\n",
      "Ignoring wrong pointing object 7 0 (offset 0)\n",
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 11 0 (offset 0)\n",
      "Ignoring wrong pointing object 13 0 (offset 0)\n",
      "Ignoring wrong pointing object 21 0 (offset 0)\n",
      "Ignoring wrong pointing object 27 0 (offset 0)\n",
      "Ignoring wrong pointing object 29 0 (offset 0)\n",
      "Ignoring wrong pointing object 56 0 (offset 0)\n",
      "Ignoring wrong pointing object 58 0 (offset 0)\n",
      "Ignoring wrong pointing object 7 0 (offset 0)\n",
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 11 0 (offset 0)\n",
      "Ignoring wrong pointing object 21 0 (offset 0)\n",
      "Ignoring wrong pointing object 23 0 (offset 0)\n",
      "Ignoring wrong pointing object 25 0 (offset 0)\n",
      "Ignoring wrong pointing object 65 0 (offset 0)\n",
      "Ignoring wrong pointing object 7 0 (offset 0)\n",
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 19 0 (offset 0)\n",
      "Ignoring wrong pointing object 21 0 (offset 0)\n",
      "Ignoring wrong pointing object 23 0 (offset 0)\n",
      "Ignoring wrong pointing object 29 0 (offset 0)\n",
      "Ignoring wrong pointing object 38 0 (offset 0)\n",
      "Ignoring wrong pointing object 40 0 (offset 0)\n",
      "Ignoring wrong pointing object 63 0 (offset 0)\n",
      "Ignoring wrong pointing object 65 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "# Load documents\n",
    "loader = DirectoryLoader('../docs', glob=\"**/*.pdf\", loader_cls=PyPDFLoader)\n",
    "documents = loader.load()\n",
    "\n",
    "# Split documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "splits = text_splitter.split_documents(documents)\n",
    "\n",
    "# Create embeddings and vector store\n",
    "embeddings = OllamaEmbeddings(model=\"llama3.2\")\n",
    "vectorstore = Chroma.from_documents(persist_directory='../chroma', documents=splits, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Initialize Llama LLM locally</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_482289/2116260297.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(persist_directory='../chroma', embedding_function=embeddings)\n",
      "/tmp/ipykernel_482289/2116260297.py:4: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama3.2\", base_url=\"http://localhost:11434\")\n"
     ]
    }
   ],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"llama3.2\")\n",
    "vectorstore = Chroma(persist_directory='../chroma', embedding_function=embeddings)\n",
    "# Initialize LLama 3.2\n",
    "llm = Ollama(model=\"llama3.2\", base_url=\"http://localhost:11434\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: ../docs/ComputerNetworkingTopDownApproach.pdf Page Number: 488\n",
      "Source: ../docs/Lecture_2_slides.pdf Page Number: 0\n",
      "Source: ../docs/book-perlner-network-security-erb.pdf Page Number: 388\n",
      "Source: ../docs/ComputerNetworkingTopDownApproach.pdf Page Number: 147\n"
     ]
    }
   ],
   "source": [
    "prompt = 'Generate a multiple choice network security quiz.'\n",
    "\n",
    "similar_docs = vectorstore.similarity_search(prompt)\n",
    "for document in similar_docs:\n",
    "    print(f\"Source: {document.metadata['source']} Page Number: {document.metadata['page']}\")\n",
    "context = \"\\n\".join([doc.page_content for doc in similar_docs])\n",
    "response = llm(f\"Context: {context}\\nQuestion: {prompt}\\nAnswer:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I can help you with each of these questions.\\n\\n1. Can an encryption algorithm map a block with given value x to a block with given value y?\\n\\nThe answer to this question depends on the specific encryption algorithm being used. In general, encryption algorithms are designed to be one-way functions, meaning that it is difficult to map a block back to its original input (x). However, some encryption algorithms may allow for reversible encryption, where an encrypted block can be decrypted back into the original input.\\n\\n2. Which of the following are possible in an encryption algorithm with decryption ability?\\n\\na) Two tuples mapping to the same ciphertext block:\\n\\nYes, this is possible. If two different keys produce the same ciphertext output, then it is likely that the encryption algorithm is vulnerable to a type of attack known as \"collision\".\\n\\nb) Two tuples with the same key producing different ciphertext blocks:\\n\\nThis is also possible. If an attacker can find a way to map different input values (block 1 and block 2) back to the same key, then it may be possible to exploit this to obtain information about the plaintext.\\n\\n3. Which SHA hash functions are vulnerable to certain attacks?\\n\\nThe following SHA hash functions are vulnerable to certain attacks:\\n\\n- MD4: vulnerable to known collision attack\\n- MD5: vulnerable to both known and birthday attacks\\n- SHA-1: vulnerable to both known and birthday attacks\\n- SHA2-256, 512: Both of these hashes are vulnerable to birthday attacks\\n\\nSHA2-224 and SHA2-384 are not considered vulnerable to the same type of attacks as the others.\\n\\n4. How would you compute a preimage in a modified version of SHA-3 with c=0?\\n\\nThe process for computing a preimage in a modified version of SHA-3, where r=1600 and c=0, is similar to that used in standard SHA-3. It involves:\\n\\n    - A 512-bit message schedule\\n    - An initial round\\n    - One or more rounds (dependent on the message length) consisting of two operations per message block (addition-subtraction or addition-multiplication)\\n    - Two final rounds consisting of addition and multiplication respectively\\n    - The output of these operations is then combined using bitwise XOR with the previous round\\'s result to produce the final preimage\\n\\nNote that in standard SHA-3 there are c bits which would be used for this purpose, but when r=1600 it becomes more complicated to get a preimage.\\n\\n5. How does the work factor depend on size of c in SHA-3?\\n\\nThe work factor for finding a preimage depends on the number of rounds and thus will depend on size of c (or at least 32 bits).'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Generate prompt with GUI using gradio</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/GIT_branches/CS5342Project/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_482289/3907343863.py:11: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = llm(f\"Context: {context}\\nQuestion: {prompt}\\nAnswer:\")\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import random\n",
    "\n",
    "def answer(message: str, history: list[str]):\n",
    "    prompt = \"\\n\".join([f\"User: {item[0]}\\nBot: {item[1]}\" for item in history]) + f\"\\nUser: {message}\\nBot:\"\n",
    "    similar_docs = vectorstore.similarity_search(prompt)\n",
    "\n",
    "    source = \"\\n\".join([f\"Source: {document.metadata['source']} Page Number: {document.metadata['page']}\" for document in similar_docs])\n",
    "\n",
    "    context = \"\\n\".join([doc.page_content for doc in similar_docs])\n",
    "    response = llm(f\"Context: {context}\\nQuestion: {prompt}\\nAnswer:\")\n",
    "    history.append([message, response])\n",
    "\n",
    "    return (response + \"\\n\\n\" + source)\n",
    "\n",
    "\n",
    "chatbot = gr.ChatInterface(\n",
    "    fn=answer,\n",
    "    title=\"Group 5 Quizbot\",\n",
    "    description=\"Enter the following prompt to be quizzed: Generate a multiple choice, true/false, or short answer network security question and provide feedback to my answer.\"\n",
    ")\n",
    "\n",
    "chatbot.launch(server_port=7860)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
